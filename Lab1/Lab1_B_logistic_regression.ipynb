{"cells":[{"cell_type":"markdown","metadata":{"id":"dGmTzE_rvoPE"},"source":["# MMI_2024_NLP - Week 1\n","\n","#Lab 1: Part 2"]},{"cell_type":"markdown","metadata":{"id":"E6295bUoqSbf"},"source":["# (B) Logistic Regression Model"]},{"cell_type":"markdown","metadata":{"id":"p5uCE1MSm7br"},"source":["In this second part of the lab, we will implement a language identifier trained on the same data, but using Logistic Regression instead of Naive Bayes."]},{"cell_type":"code","execution_count":150,"metadata":{"id":"tnQyS9w9m7bu"},"outputs":[],"source":["import io, sys, math\n","import numpy as np\n","from collections import defaultdict\n","from tqdm.notebook import tqdm,trange\n","from typing import Tuple, List, Dict\n","import random"]},{"cell_type":"markdown","metadata":{"id":"SqHxJJa7m7bv"},"source":["This function is used to build the dictionary, or vocabulary, which is a mapping from strings (or words) to integers (or indices). This will allow to build vector representations of documents."]},{"cell_type":"code","execution_count":151,"metadata":{"id":"-vXdFjspm7bv"},"outputs":[],"source":["def build_dict(filename:str, threshold:int=1)->Tuple[Dict]:\n","    \"\"\"\n","    Input:\n","    - filename: the name of the data file.\n","    - threshold: is the minimum number of times the word has to appear in the data to be added to the vocabulary.\n","    Output:\n","    - word_dict: the vocabulary generated from the dataset.\n","    - label_dict: the dictionary of the labels, with labels as keys and their indices as values of these keys.\n","    \"\"\"\n","    fin = io.open(filename, 'r', encoding='utf-8')\n","    word_dict, label_dict = {}, {}\n","    counts = defaultdict(lambda: 0)\n","    for line in tqdm(fin):\n","        tokens = line.split()\n","        label = tokens[0]\n","\n","        if not label in label_dict:\n","            label_dict[label] = len(label_dict)\n","\n","        for w in tokens[1:]:\n","            counts[w] += 1\n","\n","    for k, v in counts.items():\n","        if v > threshold:\n","            word_dict[k] = len(word_dict)\n","    return word_dict, label_dict"]},{"cell_type":"markdown","metadata":{"id":"5nIdAGsum7bw"},"source":["This function is used to load the training dataset, and build vector representations of the training examples. In particular, a document or sentence is represented as a bag of words. Each example correspond to a sparse vector ` x` of dimension `V`, where `V` is the size of the vocabulary. The element `j` of the vector `x` is the number of times the word `j` appears in the document."]},{"cell_type":"code","execution_count":152,"metadata":{"id":"HgcK2pRrm7bw"},"outputs":[],"source":["def load_data(filename:str, word_dict:Dict, label_dict:Dict)->List[Tuple]:\n","    fin = io.open(filename, 'r', encoding='utf-8')\n","    data = []\n","    dim = len(word_dict) #The size of the vocabulary.\n","    for line in tqdm(fin):\n","        tokens = line.split() #Consider tokenization by space in this case.\n","        label = tokens[0]\n","\n","        yi = label_dict[label]\n","        xi = np.zeros(dim)\n","        for word in tokens[1:]:\n","            if word in word_dict:\n","                wid = word_dict[word]\n","                xi[wid] += 1.0\n","        data.append((yi, xi))\n","    return data"]},{"cell_type":"markdown","metadata":{"id":"DgKPoEmQm7bx"},"source":["First, let's implement the softmax function. Don't forget numerical stability!"]},{"cell_type":"code","execution_count":153,"metadata":{"id":"XXZcrv0im7bx"},"outputs":[],"source":["import numpy as np\n","\n","# def softmax(x: np.ndarray) -> np.ndarray:\n","#     ##########################################################################\n","#     #                      TODO: Implement this function                     #\n","#     ##########################################################################\n","#     # Subtract the maximum value from each row for numerical stability\n","#     x_max = np.max(x)\n","#     e_x = np.exp(x - x_max)\n","#     softmax_output = e_x / np.sum(e_x, axis=1, keepdims=True)\n","#     ##########################################################################\n","#     #                            END OF YOUR CODE                            #\n","#     ##########################################################################\n","#     return softmax_output\n","def softmax(x:np.ndarray)->np.ndarray:\n","  ##########################################################################\n","  #                      TODO: Implement this function                     #\n","  ##########################################################################\n","  # Replace \"pass\" statement with your code\n","    c = np.max(x)\n","    \n","    log_sum_exp = c + np.log(np.sum(np.exp(x - c),-1,keepdims=True))\n","\n","    return np.exp(x - log_sum_exp)\n","  ##########################################################################\n","  #                            END OF YOUR CODE                            #\n","  ##########################################################################"]},{"cell_type":"markdown","metadata":{"id":"_1YF7GrOm7bx"},"source":["Now, let's implement the main training loop, by using stochastic gradient descent. The function will iterate over the examples of the training set. For each example, we will first compute the loss, before computing the gradient and performing the update."]},{"cell_type":"code","execution_count":154,"metadata":{},"outputs":[],"source":["import numpy as np\n","import random\n","from typing import List, Tuple\n","from tqdm import trange\n","\n","def sgd(w: np.ndarray, data: List[Tuple[np.ndarray, int]], niter: int, lr: float = 0.001) -> np.ndarray:\n","    \"\"\"\n","    Input:\n","    - w: the weight matrix of shape (length of label dictionary, length of word dictionary)\n","    - data: the dataset.\n","    - niter: number of epochs, or number of passes on the all dataset.\n","    - lr: the learning rate.\n","\n","    Output:\n","    - w: the weight matrix.\n","    \"\"\"\n","    random.seed(123)\n","    nlabels, dim = w.shape\n","    loss_list = []\n","\n","    for _ in trange(niter):\n","        random.shuffle(data)\n","        \n","        total_loss = 0\n","        for y, x in data:\n","            # print(x.shape)\n","            # Compute the scores\n","            #scores = np.dot(w, x)\n","            \n","            # Compute the probabilities\n","            probs = predict(w,x)#.flatten()\n","            \n","            # Compute the loss (cross-entropy loss)\n","            #y = y.astype('int')\n","            loss = -np.log(probs[y])\n","            total_loss += loss\n","            \n","            # Compute the gradient\n","            grad = probs.copy()\n","            grad[y] -= 1\n","            #print(x.shape, grad.shape)\n","            grad = grad.reshape(-1,1) * x.reshape(1, -1)\n","            #print(grad.shape)\n","            # Update the weights\n","            w -= lr * grad\n","        print(total_loss / len(data))  \n","        loss_list.append(total_loss / len(data))\n","        \n","\n","    return w#, loss_list"]},{"cell_type":"markdown","metadata":{"id":"RfrLiyCTm7by"},"source":["The next function will predict the most probable label corresponding to example `x`, given the trained classifier `w`."]},{"cell_type":"code","execution_count":155,"metadata":{"id":"uMHNaYB4m7by"},"outputs":[],"source":["def predict(w: np.ndarray, x: np.ndarray) -> int:\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Compute the scores\n","    scores = np.dot(w, x)\n","    \n","    # Compute the probabilities\n","    probs = softmax(scores).flatten()\n","    \n","    # Predict the label with the highest probability\n","    #predicted_label = np.argmax(probs)\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################\n","    \n","    return probs#predicted_label"]},{"cell_type":"markdown","metadata":{"id":"R897_5jJm7by"},"source":["Finally, this function will compute the accuracy of a trained classifier `w` on a validation set."]},{"cell_type":"code","execution_count":156,"metadata":{"id":"2I9tYxCBm7by"},"outputs":[],"source":["def compute_accuracy(w: np.ndarray, valid_data: List[Tuple[np.ndarray, int]]) -> float:\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    correct_predictions = 0\n","    total_predictions = len(valid_data)\n","    \n","    for y, x in valid_data:\n","        predicted_label = predict(w, x)\n","        if np.argmax(predicted_label) == y:\n","            correct_predictions += 1\n","    \n","    accuracy = correct_predictions / total_predictions\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################\n","    \n","    return accuracy"]},{"cell_type":"code","execution_count":157,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":119,"referenced_widgets":["8160219b08744de0ac98939651e0ffc4","245f40680d4449cca9c27195531dd9f7","8455add820404f5c956d69b555db5220","5d04ccbe01b54a24b2e54f71534ddd99","5cc69669e6af483e982d4907f67a1c6a","e6ffc075c3f6461fae9746437d6064c9","43fd682975804e62beecc55c8b1ac9a0","34db7fbe2bff45a3a75808e8810aafd9","ec52a54607514da7843fd506fe889a9d","1b15e60cde8e4ac688689a7aa1e43426","155b2299d2c2402b88e30eec737c1456"]},"id":"0ynmky3nm7by","outputId":"2d78bb4d-501b-494f-9dac-23b6d15376cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","** Logistic Regression **\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fcb160fdb7494e0dad306ced17dbb75e","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71c07f7536954d1fab1d3d476cfa7e7f","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b3626f9f0a947b2a1a5e2e26d7af491","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["10000\n"]},{"name":"stderr","output_type":"stream","text":["  5%|▌         | 1/20 [02:33<48:27, 153.05s/it]"]},{"name":"stdout","output_type":"stream","text":["2.170989652456757\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|█         | 2/20 [03:52<32:53, 109.62s/it]"]},{"name":"stdout","output_type":"stream","text":["1.9609525434155675\n"]},{"name":"stderr","output_type":"stream","text":[" 15%|█▌        | 3/20 [05:17<27:50, 98.27s/it] "]},{"name":"stdout","output_type":"stream","text":["1.814166025440323\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|██        | 4/20 [06:54<26:07, 97.96s/it]"]},{"name":"stdout","output_type":"stream","text":["1.7015617874079856\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|██▌       | 5/20 [08:39<25:08, 100.56s/it]"]},{"name":"stdout","output_type":"stream","text":["1.6095158060959445\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|███       | 6/20 [10:26<23:58, 102.76s/it]"]},{"name":"stdout","output_type":"stream","text":["1.5317479493586756\n"]},{"name":"stderr","output_type":"stream","text":[" 35%|███▌      | 7/20 [12:07<22:05, 101.96s/it]"]},{"name":"stdout","output_type":"stream","text":["1.4646650935126033\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|████      | 8/20 [13:49<20:27, 102.28s/it]"]},{"name":"stdout","output_type":"stream","text":["1.4059572801703397\n"]},{"name":"stderr","output_type":"stream","text":[" 45%|████▌     | 9/20 [15:32<18:44, 102.23s/it]"]},{"name":"stdout","output_type":"stream","text":["1.3540256235961516\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|█████     | 10/20 [17:16<17:09, 103.00s/it]"]},{"name":"stdout","output_type":"stream","text":["1.3076669791312625\n"]},{"name":"stderr","output_type":"stream","text":[" 55%|█████▌    | 11/20 [18:37<14:25, 96.16s/it] "]},{"name":"stdout","output_type":"stream","text":["1.2659639987722109\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|██████    | 12/20 [20:18<13:00, 97.52s/it]"]},{"name":"stdout","output_type":"stream","text":["1.228198333785034\n"]},{"name":"stderr","output_type":"stream","text":[" 65%|██████▌   | 13/20 [21:56<11:23, 97.68s/it]"]},{"name":"stdout","output_type":"stream","text":["1.1937932970545346\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|███████   | 14/20 [23:42<10:02, 100.40s/it]"]},{"name":"stdout","output_type":"stream","text":["1.1622803308649672\n"]},{"name":"stderr","output_type":"stream","text":[" 75%|███████▌  | 15/20 [25:08<07:59, 95.83s/it] "]},{"name":"stdout","output_type":"stream","text":["1.1332783728795672\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|████████  | 16/20 [26:45<06:25, 96.38s/it]"]},{"name":"stdout","output_type":"stream","text":["1.1064699896891959\n"]},{"name":"stderr","output_type":"stream","text":[" 85%|████████▌ | 17/20 [28:07<04:36, 92.03s/it]"]},{"name":"stdout","output_type":"stream","text":["1.0815957723845266\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|█████████ | 18/20 [29:35<03:01, 90.84s/it]"]},{"name":"stdout","output_type":"stream","text":["1.0584298512414623\n"]},{"name":"stderr","output_type":"stream","text":[" 95%|█████████▌| 19/20 [31:06<01:30, 90.73s/it]"]},{"name":"stdout","output_type":"stream","text":["1.0367805974339883\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [32:31<00:00, 97.57s/it]"]},{"name":"stdout","output_type":"stream","text":["1.0164917414673957\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","Validation accuracy: 0.877\n","\n"]}],"source":["print(\"\")\n","print(\"** Logistic Regression **\")\n","print(\"\")\n","\n","word_dict, label_dict = build_dict(\"train1.txt\")\n","train_data = load_data(\"train1.txt\", word_dict, label_dict)\n","valid_data = load_data(\"valid1.txt\", word_dict, label_dict)\n","print(len(train_data))\n","nlabels = len(label_dict)\n","\n","dim = len(word_dict)\n","w = np.zeros([nlabels, dim])\n","w = sgd(w, train_data, 20)\n","print(\"\")\n","print(\"Validation accuracy: %.3f\" % compute_accuracy(w, valid_data))\n","print(\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SAqRAq38NTVC"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"DAaC78iUPf13"},"source":["# Recommended Reading:\n","\n","- https://people.tamu.edu/~sji/classes/LR.pdf\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.1.-1"},"widgets":{"application/vnd.jupyter.widget-state+json":{"155b2299d2c2402b88e30eec737c1456":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b15e60cde8e4ac688689a7aa1e43426":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"245f40680d4449cca9c27195531dd9f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6ffc075c3f6461fae9746437d6064c9","placeholder":"​","style":"IPY_MODEL_43fd682975804e62beecc55c8b1ac9a0","value":"Epoch 1/5 Loss 11.934367527601534:   3%"}},"34db7fbe2bff45a3a75808e8810aafd9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43fd682975804e62beecc55c8b1ac9a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5cc69669e6af483e982d4907f67a1c6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d04ccbe01b54a24b2e54f71534ddd99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b15e60cde8e4ac688689a7aa1e43426","placeholder":"​","style":"IPY_MODEL_155b2299d2c2402b88e30eec737c1456","value":" 305/10000 [00:02&lt;01:02, 154.50it/s]"}},"8160219b08744de0ac98939651e0ffc4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_245f40680d4449cca9c27195531dd9f7","IPY_MODEL_8455add820404f5c956d69b555db5220","IPY_MODEL_5d04ccbe01b54a24b2e54f71534ddd99"],"layout":"IPY_MODEL_5cc69669e6af483e982d4907f67a1c6a"}},"8455add820404f5c956d69b555db5220":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_34db7fbe2bff45a3a75808e8810aafd9","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec52a54607514da7843fd506fe889a9d","value":306}},"e6ffc075c3f6461fae9746437d6064c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec52a54607514da7843fd506fe889a9d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
